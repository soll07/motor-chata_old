{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-02-04T07:43:56.395135600Z",
     "start_time": "2026-02-04T07:43:50.762228800Z"
    }
   },
   "source": [
    "!pip install requests beautifulsoup4\n",
    "from urllib3.poolmanager import key_fn_by_scheme\n",
    "!pip install selenium\n",
    "!pip install pymysql"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\playdata\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (2.32.5)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\playdata\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (4.14.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\playdata\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from requests) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\playdata\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from requests) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\playdata\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from requests) (2.6.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\playdata\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from requests) (2026.1.4)\n",
      "Requirement already satisfied: soupsieve>=1.6.1 in c:\\users\\playdata\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from beautifulsoup4) (2.8.3)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\playdata\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from beautifulsoup4) (4.15.0)\n",
      "Requirement already satisfied: selenium in c:\\users\\playdata\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (4.40.0)\n",
      "Requirement already satisfied: certifi>=2026.1.4 in c:\\users\\playdata\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from selenium) (2026.1.4)\n",
      "Requirement already satisfied: trio<1.0,>=0.31.0 in c:\\users\\playdata\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from selenium) (0.32.0)\n",
      "Requirement already satisfied: trio-websocket<1.0,>=0.12.2 in c:\\users\\playdata\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from selenium) (0.12.2)\n",
      "Requirement already satisfied: trio-typing>=0.10.0 in c:\\users\\playdata\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from selenium) (0.10.0)\n",
      "Requirement already satisfied: types-certifi>=2021.10.8.3 in c:\\users\\playdata\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from selenium) (2021.10.8.3)\n",
      "Requirement already satisfied: types-urllib3>=1.26.25.14 in c:\\users\\playdata\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from selenium) (1.26.25.14)\n",
      "Requirement already satisfied: typing_extensions<5.0,>=4.15.0 in c:\\users\\playdata\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from selenium) (4.15.0)\n",
      "Requirement already satisfied: urllib3<3.0,>=2.6.3 in c:\\users\\playdata\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from urllib3[socks]<3.0,>=2.6.3->selenium) (2.6.3)\n",
      "Requirement already satisfied: websocket-client<2.0,>=1.8.0 in c:\\users\\playdata\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from selenium) (1.9.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\playdata\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium) (25.4.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\playdata\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\playdata\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium) (3.11)\n",
      "Requirement already satisfied: outcome in c:\\users\\playdata\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\playdata\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\playdata\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from trio<1.0,>=0.31.0->selenium) (2.0.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\playdata\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from trio-websocket<1.0,>=0.12.2->selenium) (1.3.2)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\playdata\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from urllib3[socks]<3.0,>=2.6.3->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\playdata\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from cffi>=1.14->trio<1.0,>=0.31.0->selenium) (2.22)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.2 in c:\\users\\playdata\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from trio-typing>=0.10.0->selenium) (1.1.0)\n",
      "Requirement already satisfied: async-generator in c:\\users\\playdata\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from trio-typing>=0.10.0->selenium) (1.10)\n",
      "Requirement already satisfied: packaging in c:\\users\\playdata\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from trio-typing>=0.10.0->selenium) (26.0)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\playdata\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from trio-typing>=0.10.0->selenium) (8.7.0)\n",
      "Requirement already satisfied: h11<1,>=0.16.0 in c:\\users\\playdata\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from wsproto>=0.14->trio-websocket<1.0,>=0.12.2->selenium) (0.16.0)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\playdata\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from importlib-metadata->trio-typing>=0.10.0->selenium) (3.23.0)\n",
      "Requirement already satisfied: pymysql in c:\\users\\playdata\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (1.1.2)\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import time\n",
    "import json\n",
    "import requests\n",
    "import pymysql\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "DB_CONFIG = {\n",
    "    \"host\": \"192.168.76.xxx\",\n",
    "    \"user\": \"wohhahha\",\n",
    "    \"password\": \"wohhahha\",\n",
    "    \"db\": \"motor_chata\",\n",
    "    \"charset\": \"utf8mb4\",\n",
    "}\n",
    "\n",
    "LIST_URL = \"https://www.car.go.kr/ri/stat/list.do\"\n",
    "DETAIL_URL = \"https://www.car.go.kr/ri/stat/detail.do\"\n",
    "\n",
    "TARGET_BRANDS = [\n",
    "    \"ê¸°ì•„\", \"í˜„ëŒ€\", \"ì œë„¤ì‹œìŠ¤\",\n",
    "    \"ì¼€ì´ì§€ëª¨ë¹Œë¦¬í‹°\", \"ì¼€ì´ì§€\", \"KG\",\n",
    "    \"ë¥´ë…¸\", \"ë¥´ë…¸ì½”ë¦¬ì•„\",\n",
    "    \"ë²¤ì¸ \",\n",
    "    \"ë¹„ì— ë”ë¸”ìœ \", \"BMW\",\n",
    "    \"í…ŒìŠ¬ë¼\",\n",
    "    \"ë³¼ë³´\",\n",
    "    \"BYD\", \"BYDì½”ë¦¬ì•„\", \"ë¹„ì™€ì´ë””\",\n",
    "]\n",
    "\n",
    "LAST_PAGE = 864\n"
   ],
   "id": "6f3794be0dcc85be"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "conn = pymysql.connect(**DB_CONFIG)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "insert_sql = \"\"\"\n",
    "INSERT INTO recall_info (\n",
    "    page_no, maker, title, recall_id, ctype,\n",
    "    maker_detail, car_name, ìƒì‚°ê¸°ê°„, ì‹œì •ê¸°ê°„,\n",
    "    ëŒ€ìƒìˆ˜ëŸ‰, ì¥ì¹˜ë¶„ë¥˜, ê²°í•¨ë‚´ìš©, ì‹œì •ë°©ë²•, ê¸°íƒ€ë¬¸ì˜\n",
    ")\n",
    "VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "print(\"DB ì—°ê²° ì™„ë£Œ\")\n"
   ],
   "id": "adbacf9dbe2b8fb6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "# Selenium ë“œë¼ì´ë²„\n",
    "driver = webdriver.Chrome()\n",
    "driver.implicitly_wait(5)\n",
    "driver.get(LIST_URL)\n",
    "\n",
    "# detail.doìš© requests ì„¸ì…˜\n",
    "session = requests.Session()\n",
    "session.headers.update({\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\",\n",
    "    \"Referer\": LIST_URL,\n",
    "    \"Origin\": \"https://www.car.go.kr\",\n",
    "})\n",
    "\n",
    "# ì¿ í‚¤ ë§ì¶”ë ¤ê³  í•œ ë²ˆ GET\n",
    "session.get(LIST_URL)\n",
    "\n",
    "print(\"Selenium & requests ì¤€ë¹„ ì™„ë£Œ\")\n"
   ],
   "id": "901b3d1f206623d1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "def parse_maker_title(title_full: str):\n",
    "    \"\"\"[ì œì‘ì‚¬] ì œëª© â†’ (maker, title) ë¶„ë¦¬\"\"\"\n",
    "    maker = \"\"\n",
    "    title = title_full.strip()\n",
    "    if \"[\" in title_full and \"]\" in title_full:\n",
    "        maker = title_full.split(\"]\")[0].replace(\"[\", \"\").strip()\n",
    "        title = title_full.split(\"]\")[1].strip()\n",
    "    return maker, title\n",
    "\n",
    "\n",
    "def parse_onclick(onclick_value: str):\n",
    "    \"\"\"\n",
    "    $main.event.detailView('5869','O'); return false;\n",
    "    ì´ëŸ° ë¬¸ìì—´ì—ì„œ recall_id, ctype ì¶”ì¶œ\n",
    "    \"\"\"\n",
    "    if \"detailView\" not in onclick_value:\n",
    "        return None, None\n",
    "\n",
    "    inner = onclick_value.split(\"detailView(\")[1].split(\")\")[0]\n",
    "    parts = [p.strip().strip(\"'\") for p in inner.split(\",\")]\n",
    "    if len(parts) >= 2:\n",
    "        return parts[0], parts[1]\n",
    "    return None, None\n",
    "\n",
    "\n",
    "def fetch_detail_html(session: requests.Session, recall_id: str, ctype: str = \"O\") -> str:\n",
    "    \"\"\"detail.do ì— POSTë¡œ ìš”ì²­í•´ì„œ HTML ì „ì²´ë¥¼ ë¬¸ìì—´ë¡œ ë°˜í™˜\"\"\"\n",
    "    payload = {\n",
    "        \"currentPageNo\": \"\",\n",
    "        \"ctype\": ctype,\n",
    "        \"searchOriginalMakerName\": \"\",\n",
    "        \"searchOriginalMakerCode\": \"\",\n",
    "        \"searchProductName\": \"\",\n",
    "        \"searchFromDate\": \"\",\n",
    "        \"searchToDate\": \"\",\n",
    "        \"recallId\": recall_id,\n",
    "    }\n",
    "\n",
    "    resp = session.post(DETAIL_URL, data=payload)\n",
    "    if resp.status_code != 200:\n",
    "        print(f\"âš  detail.do í˜¸ì¶œ ì‹¤íŒ¨ {resp.status_code} / recallId={recall_id}\")\n",
    "        return \"\"\n",
    "\n",
    "    return resp.text\n",
    "\n",
    "\n",
    "def parse_detail_table(html: str) -> dict:\n",
    "    \"\"\"ìƒì„¸í˜ì´ì§€ì˜ í‘œ â†’ dict í˜•íƒœë¡œ íŒŒì‹±\"\"\"\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    result = {}\n",
    "\n",
    "    table = soup.find(\"table\", class_=\"table-stat\")\n",
    "    if not table:\n",
    "        return result\n",
    "\n",
    "    tbody = table.find(\"tbody\")\n",
    "    if not tbody:\n",
    "        return result\n",
    "\n",
    "    for tr in tbody.find_all(\"tr\"):\n",
    "        th_tags = tr.find_all(\"th\")\n",
    "        td_tags = tr.find_all(\"td\")\n",
    "\n",
    "        for th, td in zip(th_tags, td_tags):\n",
    "            key = th.get_text(strip=True)\n",
    "            val = td.get_text(\"\\n\", strip=True)\n",
    "            if key:\n",
    "                result[key] = val\n",
    "\n",
    "    return result"
   ],
   "id": "62cc661ded0567ba"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "total_saved = 0\n",
    "\n",
    "for page in range(1, LAST_PAGE + 1):\n",
    "    print(f\"\\n=== {page} í˜ì´ì§€ ===\")\n",
    "\n",
    "    if page != 1:\n",
    "        driver.execute_script(f\"$main.event.fn_search({page});\")\n",
    "        time.sleep(1)\n",
    "\n",
    "    items = driver.find_elements(By.CSS_SELECTOR, \"ul.board-hrznt-list > li\")\n",
    "    print(\"ë¦¬ì½œ ê±´ìˆ˜:\", len(items))\n",
    "\n",
    "    for li_tag in items:\n",
    "        a_tag = li_tag.find_element(By.CSS_SELECTOR, \"a\")\n",
    "        strong_tag = a_tag.find_element(By.CSS_SELECTOR, \"strong\")\n",
    "\n",
    "        title_full = strong_tag.text.strip()\n",
    "        maker, title = parse_maker_title(title_full)\n",
    "\n",
    "        # ë¸Œëœë“œ í•„í„°ë§\n",
    "        if not any(keyword in maker for keyword in TARGET_BRANDS):\n",
    "            continue\n",
    "\n",
    "        onclick_val = a_tag.get_attribute(\"onclick\") or \"\"\n",
    "        recall_id, ctype = parse_onclick(onclick_val)\n",
    "\n",
    "        if not recall_id:\n",
    "            print(\"âš  recall_id ì¶”ì¶œ ì‹¤íŒ¨\")\n",
    "            continue\n",
    "\n",
    "        # ìƒì„¸ HTML ê°€ì ¸ì˜¤ê¸°\n",
    "        detail_html = fetch_detail_html(session, recall_id, ctype)\n",
    "        detail_info = parse_detail_table(detail_html)\n",
    "\n",
    "        # ğŸ”¥ INSERT â€” ì»¬ëŸ¼ë§Œ ì €ì¥ (14ê°œ)\n",
    "        cursor.execute(\n",
    "            insert_sql,\n",
    "            (\n",
    "                page,                  # page_no\n",
    "                maker,                 # maker\n",
    "                title,                 # title\n",
    "                recall_id,             # recall_id\n",
    "                ctype,                 # ctype\n",
    "                detail_info.get(\"ì œì‘(ìˆ˜ì…)ì‚¬\"),\n",
    "                detail_info.get(\"ì°¨ëª…\"),\n",
    "                detail_info.get(\"ìƒì‚°ê¸°ê°„\"),\n",
    "                detail_info.get(\"ì‹œì •ê¸°ê°„\"),\n",
    "                detail_info.get(\"ëŒ€ìƒìˆ˜ëŸ‰\"),\n",
    "                detail_info.get(\"ì¥ì¹˜ë¶„ë¥˜\"),\n",
    "                detail_info.get(\"ê²°í•¨ë‚´ìš©\"),\n",
    "                detail_info.get(\"ì‹œì •ë°©ë²•\"),\n",
    "                detail_info.get(\"ê¸°íƒ€ë¬¸ì˜\"),\n",
    "            )\n",
    "        )\n",
    "\n",
    "        total_saved += 1\n",
    "        print(f\"[ì €ì¥] p{page} | {maker} | {title} | id={recall_id}\")\n",
    "        time.sleep(0.2)\n",
    "\n",
    "conn.commit()\n",
    "cursor.close()\n",
    "conn.close()\n",
    "driver.quit()\n",
    "\n",
    "print(\"\\ní¬ë¡¤ë§ ì™„ë£Œ\")\n",
    "print(\"ì´ ì €ì¥ ê±´ìˆ˜:\", total_saved)\n"
   ],
   "id": "bc06393ce6c7060f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pymysql\n",
    "import pandas as pd\n",
    "\n",
    "conn = pymysql.connect(**DB_CONFIG)\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute(\"SELECT * FROM recall_info\")\n",
    "rows = cur.fetchall()\n",
    "\n",
    "# ì»¬ëŸ¼ëª… ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "cols = [desc[0] for desc in cur.description]\n",
    "\n",
    "# DataFrame ë§Œë“¤ê¸°\n",
    "df = pd.DataFrame(rows, columns=cols)\n",
    "\n",
    "cur.close()\n",
    "conn.close()\n",
    "\n",
    "# ğŸ”¥ ì—¬ê¸° ë°”ë¡œ ì•„ë˜ì— CSV ì €ì¥\n",
    "df.to_csv(\"recall.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "print(\"CSV ì €ì¥ ì™„ë£Œ\")\n"
   ],
   "id": "230a9d02f136def2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
